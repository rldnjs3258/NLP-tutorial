##  21) 모델 생성 : Naive Bayes

```python
  # 라이브러리 로드
  from sklearn.naive_bayes import MultinomialNbB #Naive Bayes

  # 모델 생성 및 예측
  nb_classifier = MultinomialNB().fit(X_train, y_train) #fit을 이용하여 모델 학습
  nb_pred = nb_classifier.predict(x_test) #예측

  # 성능 평가
  print(confusion_matrix(y_test, nb_pred)) #실제 값과 예측값을 비교한다.
  print(classification_report(y_test, nb_pred))
  print(round(accuracy_score(y_test, nb_pred, normalize = True), 2)) #normalize를 True로 설정하면 정확도를, False로 설정하면 올바르게 분류된 데이터의 건수를 출력한다. round 함수로 소수점 2까지 출력!
```

<br>
<hr>
<br>


##  22) 성능 저장 : Naive Bayes

```python
  fm = round(f1_score(y_test, nb_pred, average='weighted', 2) #실제 값과 결과값을 비교해 f-measure을 계산하고, average = 'weight'로 설정해 클래스 별 가중치 적용. round로 소수점 2자리까지 표시.
  ac = round(accuracy_score(y_test, nb_pred, normalize = True), 2) #실제 값과 결과 값을 비교해 accuracy를 계산하고, normalizer = True를 사용해 정확도를 출력. round로 소수점 2자리까지 표시.
  df_per.loc[len(df_per)] = ['Naive Bayes', fm, ac] #df_per에 Naive Bayes의 성능을 저장!
```

<br>
<hr>
<br>


##  23) 모델 생성 : Decision Tree Classifier

```python
  # 라이브러리 로드
  From sklearn.tree import DecisionTreeClassifier

  # 모델 생성 및 예측
  dt_classifier = DecisionTreeClassifier().fit(X_train, y_train)
  dt_pred = dt_classifier.predict(X_test)

  # 성능 평가
  print(confusion matrix(y_test, dt_pred))
  print(classification_report(y_test, dt_pred))
  print(round(accuracy_score(y_test, dt_pred, normalize = True), 2))
```

<br>
<hr>
<br>


##  24) 성능 저장 : Decision Tree Classifier

```python
  fm = round(f1_score(y_test, dt_pred, average='weighted', 2)
  ac = round(accuracy_score(y_test, dt_pred, normalize = True), 2)
  df_per.loc[len(df_per)] = ['Decision Tree', fm, ac] #df_per에 Decision Tree의 성능을 저장!
```

<br>
<hr>
<br>


##  25) 모델 생성 : Random Forest Classifier

```python
  # 라이브러리 로드
  from sklearn.ensemble import RandomForestClassifier

  # 모델 생성 및 예측
  rf_classifier = RandomForestClassifier(n_estimators = 100)
  rf_classifier.fit(X_train, y_train)

  # 성능 평가
  print(confusion matrix(y_test, rf_pred))
  print(classification_report(y_test, rf_pred))
  print(round(accuracy_score(y_test, rf_pred, normalize = True), 2))
```

<br>
<hr>
<br>


##  26) 성능 저장 : Random Forest Classifier

```python
  fm = round(f1_score(y_test, rf_pred, average='weighted', 2)
  ac = round(accuracy_score(y_test, rf_pred, normalize = True), 2)
  df_per.loc[len(df_per)] = ['Random Forest', fm, ac] #df_per에 Random Forest의 성능을 저장!
```

<br>
<hr>
<br>


##  27) 모델 생성 : SVM(Support Vector Machine)

```python
  # 라이브러리 로드
  from sklearn.svm import LinearSVC

  # 모델 생성 및 예측
  svm_classifier = LinearSVC().fit(X_train, y_train)
  svm_pred = svm_classifier.predict(X_test)

  # 성능 평가
  print(confusion matrix(y_test, svm_pred))
  print(classification_report(y_test, svm_pred))
  print(round(accuracy_score(y_test, svm_pred, normalize = True), 2))
```

<br>
<hr>
<br>


##  28) 성능 저장 : SVM(Support Vector Machine)

```python
  fm = round(f1_score(y_test, svm_pred, average='weighted', 2)
  ac = round(accuracy_score(y_test, svm_pred, normalize = True), 2)
  df_per.loc[len(df_per)] = ['SVM', fm, ac] #df_per에 SVM의 성능을 저장!
```


<br>
<hr>
<br>


##  29) 성능 비교 1
   - 시각화를 위해 분류기 명을 set_index 함수를 사용해서 index로 설정한다.
   
```python
  df_per_1 = df_per.set_index('classifier')
  df_per_1
```


<br>
<hr>
<br>


##  30) 성능 비교 2 : 시각화
   - F-measure과 Accuracy 값을 plot을 통해 시각화
   
```python
  ax = df_per_1[['F-Measure', 'Accuracy']].plot(kind = 'bar', title = 'performance', figsize = (10, 7), legend = True, fontsize = 12) #kind = 'bar'로 막대 그래프 설정, 그래프 제목은 performance, 이 외에 figsize, legend, fontsize 등 설정
  ax.set_xlabel('Classifier', fontsize = 12) #그래프 x축을 분류기 명으로 설정
  plt.show() #그래프 그리기!
# 이 데이터에 대해 Random Forest의 f-measure과 accuracy가 가장 우수하다. 그 다음으로는 Decision Tree가 좋았다.
```
